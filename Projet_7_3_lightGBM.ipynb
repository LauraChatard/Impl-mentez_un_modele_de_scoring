{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author: Chatard Laura**\n",
    "\n",
    "**Modification: 19/09/2024**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization of the LightGBM Machine Learning Model\n",
    "\n",
    "This notebook is the third part of the project. Now that we have chosen the model, we will try to optimize it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# sklearn \n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve, auc, confusion_matrix, make_scorer, fbeta_score, PrecisionRecallDisplay\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import shap\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# MLflow\n",
    "#!pip install --upgrade mlflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "import time\n",
    "\n",
    "import json\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.24.3\n",
      "Pandas version: 1.5.3\n",
      "Scikit-learn version: sklearn preprocessing\n",
      "Matplotlib version: 3.9.0\n",
      "Seaborn version: 0.13.2\n",
      "MLflow version: 2.16.0\n"
     ]
    }
   ],
   "source": [
    "# Versions\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Scikit-learn version: {LabelEncoder.__module__.split('.')[0]} {LabelEncoder.__module__.split('.')[1]}\")\n",
    "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "print(f\"Seaborn version: {sns.__version__}\")\n",
    "print(f\"MLflow version: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_mat_transform(y_true, y_pred, class_labels, ax):\n",
    "    \"\"\"\n",
    "    Transforms predicted labels to match true categories \n",
    "    by maximizing values on the diagonal of the confusion matrix.\n",
    "\n",
    "    Args:\n",
    "    - y_true: True labels\n",
    "    - y_pred: Predicted labels\n",
    "    - class_labels: Labels for display\n",
    "    - ax: Matplotlib axis for plotting\n",
    "\n",
    "    Returns:\n",
    "    - y_pred_transform: Transformed predicted labels to match true categories\n",
    "    - df_cm: DataFrame of the transformed confusion matrix for display\n",
    "    \"\"\"\n",
    "    # Compute the confusion matrix\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Create the cost matrix to find the best match\n",
    "    cost_matrix = -conf_mat  # Maximize the diagonal by minimizing the cost\n",
    "    \n",
    "    # Find the best permutation of columns to maximize diagonal values\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    \n",
    "    # Reorder the columns of the confusion matrix based on the best permutation\n",
    "    conf_mat_transformed = conf_mat[:, col_ind]\n",
    "    \n",
    "    # Create a mapping between clusters and true categories\n",
    "    cluster_to_category = {i: col_ind[i] for i in range(len(col_ind))}\n",
    "    \n",
    "    # Transform predicted labels to match true categories\n",
    "    y_pred_transform = np.array([cluster_to_category[cluster] for cluster in y_pred])\n",
    "    \n",
    "    # Create a DataFrame for better visualization\n",
    "    df_cm = pd.DataFrame(conf_mat_transformed, index=class_labels, columns=class_labels)\n",
    "    \n",
    "    # Plot the confusion matrix\n",
    "    sns.heatmap(df_cm, annot=True, cmap=\"Blues\", fmt='d', ax=ax)\n",
    "    ax.set_xlabel('Predictions')\n",
    "    ax.set_ylabel('True Labels')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "    return y_pred_transform, df_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a7e9a1149953069853d4d83ec46f22084dce8711",
    "collapsed": true
   },
   "source": [
    "# MLflow tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's begin by discovering the universe of MLflow tracking. \n",
    "Here is the [documentation](https://mlflow.org/docs/latest/tracking.html) for the terms used by MLflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 471647679769818948, Name: P7_exp_LightGBM\n",
      "ID: 160787238110460711, Name: P7_exp_dummy_classifier\n",
      "ID: 150774441229989355, Name: P7_exp_random_forest\n",
      "ID: 228532471274446842, Name: P7_exp_linear_reg\n",
      "ID: 0, Name: Default\n"
     ]
    }
   ],
   "source": [
    "# Create a client MLflow\n",
    "client = MlflowClient()\n",
    "\n",
    "# List of all client\n",
    "experiments = client.search_experiments()\n",
    "\n",
    "# Print information\n",
    "for experiment in experiments:\n",
    "    print(f\"ID: {experiment.experiment_id}, Name: {experiment.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are working with 50% of datasets; without this parameter, the models don’t work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_VAR</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_VAR</th>\n",
       "      <th>CC_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16767</th>\n",
       "      <td>284060</td>\n",
       "      <td>428968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>405000.0</td>\n",
       "      <td>20250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16650</th>\n",
       "      <td>263496</td>\n",
       "      <td>405085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12274</th>\n",
       "      <td>297694</td>\n",
       "      <td>444883</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>522396.0</td>\n",
       "      <td>31239.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13060</th>\n",
       "      <td>118532</td>\n",
       "      <td>237451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>979992.0</td>\n",
       "      <td>28782.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30302</th>\n",
       "      <td>274386</td>\n",
       "      <td>418053</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>405000.0</td>\n",
       "      <td>20250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 798 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  SK_ID_CURR  TARGET  CODE_GENDER  FLAG_OWN_CAR  \\\n",
       "16767      284060      428968       0            0             0   \n",
       "16650      263496      405085       0            0             1   \n",
       "12274      297694      444883       0            1             0   \n",
       "13060      118532      237451       0            0             1   \n",
       "30302      274386      418053       0            1             0   \n",
       "\n",
       "       FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
       "16767                0             1          135000.0    405000.0   \n",
       "16650                0             1          112500.0    180000.0   \n",
       "12274                0             0          135000.0    522396.0   \n",
       "13060                0             0          225000.0    979992.0   \n",
       "30302                0             0          135000.0    405000.0   \n",
       "\n",
       "       AMT_ANNUITY  ...  CC_NAME_CONTRACT_STATUS_Signed_MAX  \\\n",
       "16767      20250.0  ...                                 0.0   \n",
       "16650       9000.0  ...                                 NaN   \n",
       "12274      31239.0  ...                                 0.0   \n",
       "13060      28782.0  ...                                 0.0   \n",
       "30302      20250.0  ...                                 NaN   \n",
       "\n",
       "       CC_NAME_CONTRACT_STATUS_Signed_MEAN  \\\n",
       "16767                                  0.0   \n",
       "16650                                  NaN   \n",
       "12274                                  0.0   \n",
       "13060                                  0.0   \n",
       "30302                                  NaN   \n",
       "\n",
       "       CC_NAME_CONTRACT_STATUS_Signed_SUM  CC_NAME_CONTRACT_STATUS_Signed_VAR  \\\n",
       "16767                                 0.0                                 0.0   \n",
       "16650                                 NaN                                 NaN   \n",
       "12274                                 0.0                                 0.0   \n",
       "13060                                 0.0                                 0.0   \n",
       "30302                                 NaN                                 NaN   \n",
       "\n",
       "       CC_NAME_CONTRACT_STATUS_nan_MIN  CC_NAME_CONTRACT_STATUS_nan_MAX  \\\n",
       "16767                              0.0                              0.0   \n",
       "16650                              NaN                              NaN   \n",
       "12274                              0.0                              0.0   \n",
       "13060                              0.0                              0.0   \n",
       "30302                              NaN                              NaN   \n",
       "\n",
       "       CC_NAME_CONTRACT_STATUS_nan_MEAN  CC_NAME_CONTRACT_STATUS_nan_SUM  \\\n",
       "16767                               0.0                              0.0   \n",
       "16650                               NaN                              NaN   \n",
       "12274                               0.0                              0.0   \n",
       "13060                               0.0                              0.0   \n",
       "30302                               NaN                              NaN   \n",
       "\n",
       "       CC_NAME_CONTRACT_STATUS_nan_VAR  CC_COUNT  \n",
       "16767                              0.0      78.0  \n",
       "16650                              NaN       NaN  \n",
       "12274                              0.0      35.0  \n",
       "13060                              0.0      40.0  \n",
       "30302                              NaN       NaN  \n",
       "\n",
       "[5 rows x 798 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample = data.sample(frac=0.5)\n",
    "data_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data\n",
    "X = data_sample.drop(columns=['TARGET'])\n",
    "y = data_sample['TARGET']\n",
    "\n",
    "# For API test we save the names of columns\n",
    "# Assuming feature_names is a list of column names\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# Save to a JSON file\n",
    "with open('feature_names.json', 'w') as f:\n",
    "    json.dump(feature_names, f)\n",
    "\n",
    "# Store feature names before transformation\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# Convertir le DataFrame en une liste de dictionnaires\n",
    "json_data = X_test.sample(frac=0.5).to_dict(orient='records')\n",
    "\n",
    "# Sauvegarder la liste de dictionnaires dans un fichier JSON\n",
    "with open('json_data.json', 'w') as f:\n",
    "    json.dump(json_data, f, indent=4)  # Utilisez indent pour une meilleure lisibilité\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Handle missing values: Impute missing values with the median and normalize the data\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save imputer and scaler\n",
    "with open('imputer.pkl', 'wb') as f:\n",
    "    pickle.dump(imputer, f)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the fact that false negatives and false positives have different costs to refine the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom weighted score function to penalize false positives and false negatives differently\n",
    "C_FN = 10  # Cost of a false negative\n",
    "C_FP = 1   # Cost of a false positive\n",
    "\n",
    "def weighted_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return (C_FN * fn + C_FP * fp) / len(y_true)\n",
    "\n",
    "# y_train contains the labels of your training data\n",
    "unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "# Calculate the frequency of each class\n",
    "class_frequencies = dict(zip(unique_classes, class_counts))\n",
    "\n",
    "# Compute class weights based on class frequency\n",
    "total_instances = len(y_train)\n",
    "weight_0 = (total_instances / (2 * class_frequencies.get(0, 1))) * C_FN\n",
    "weight_1 = (total_instances / (2 * class_frequencies.get(1, 1))) * C_FP\n",
    "\n",
    "class_weights = {0: weight_0, 1: weight_1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another approach to dealing with imbalanced data. We are testing [SMOTE](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/), which oversamples the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SMOTE for Class Imbalance\n",
    "\n",
    "# Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightBoosting\n",
    "\n",
    "After testing Random Forest, we will test the LightBoosting model. We chose it for its speed, which is an important business characteristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new experiment and get its ID\n",
    "#experiment_id = mlflow.create_experiment('P7_exp_LightGBM')\n",
    "\n",
    "# ID\n",
    "P7_exp_LightGBM = \"471647679769818948\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Calculate scale_pos_weight\n",
    "#Assuming y_train is a pandas Series or can be converted to one\n",
    "y_train_series = pd.Series(y_train)\n",
    "\n",
    "#Number of negative samples (class label 0à\n",
    "num_negative_samples = (y_train_series == 0).sum()\n",
    "\n",
    "#Number of positive samples\n",
    "num_positive_samples = (y_train_series == 1).sum()\n",
    "scale_pos_weight = num_negative_samples / num_positive_samples\n",
    "\n",
    "#Define the LightGBM model with scale_pos_weight\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    metric='binary_logloss',\n",
    "    random_state=42,\n",
    "    scale_pos_weight=scale_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LightGBM model\n",
    "lgb_model = lgb.LGBMClassifier(class_weight=class_weights, objective='binary', metric='binary_logloss',\n",
    "                               random_state=42, verbose=0)\n",
    "\n",
    "# Define the pipeline and grid search\n",
    "pipeline = Pipeline([\n",
    "    ('classifier', lgb_model)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [10, 20],\n",
    "    'classifier__learning_rate': [0.01, 0.1],\n",
    "    'classifier__num_leaves': [31, 63]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the experiment with MLflow\n",
    "with mlflow.start_run(run_name=\"LightGBM_SMOTE\", experiment_id=P7_exp_LightGBM):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Run GridSearchCV to find the best hyperparameters\n",
    "    grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "    # Log training time\n",
    "    training_time = time.time() - start_time\n",
    "    mlflow.log_metric(\"training_time\", training_time)\n",
    "\n",
    "    # Get the best model from the grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate the best model on the test set\n",
    "    start_time = time.time()\n",
    "    y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    threshold = 0.5\n",
    "    y_pred = (y_pred_proba > threshold).astype(int)\n",
    "    prediction_time = time.time() - start_time\n",
    "    mlflow.log_metric(\"prediction_time\", prediction_time)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    weighted_score_val = weighted_score(y_test, y_pred)\n",
    "    beta_score = fbeta_score(y_test, y_pred, average='macro', beta=2)\n",
    "\n",
    "    # Log parameters and metrics in MLflow\n",
    "    mlflow.log_param(\"best_n_estimators\", grid_search.best_params_['classifier__n_estimators'])\n",
    "    mlflow.log_param(\"best_max_depth\", grid_search.best_params_['classifier__max_depth'])\n",
    "    mlflow.log_param(\"best_learning_rate\", grid_search.best_params_['classifier__learning_rate'])\n",
    "    mlflow.log_param(\"best_num_leaves\", grid_search.best_params_['classifier__num_leaves'])\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision_recall_auc\", pr_auc)\n",
    "    mlflow.log_metric(\"weighted_score\", weighted_score_val)\n",
    "    mlflow.log_metric(\"beta_score\", beta_score)\n",
    "\n",
    "    # Save the precision-recall curve as an artifact\n",
    "    plt.figure()\n",
    "    PrecisionRecallDisplay(precision, recall).plot()\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.savefig(\"precision_recall_curve.png\")\n",
    "    mlflow.log_artifact(\"precision_recall_curve.png\")\n",
    "\n",
    "    # Save the confusion matrix as an artifact using the custom function\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    y_pred_transform, df_cm = conf_mat_transform(y_test, y_pred, class_labels=['Class 0', 'Class 1'], ax=ax)\n",
    "    plt.savefig(\"confusion_matrix.png\")\n",
    "    mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "\n",
    "    # Log the best model in MLflow\n",
    "    mlflow.sklearn.log_model(best_model, \"best_model\")\n",
    "\n",
    "    # Save the best parameters as an artifact\n",
    "    with open(\"best_model_params.txt\", \"w\") as f:\n",
    "        f.write(str(grid_search.best_params_))\n",
    "    mlflow.log_artifact(\"best_model_params.txt\")\n",
    "\n",
    "    # Save the metrics as a JSON file\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision_recall_auc\": pr_auc,\n",
    "        \"weighted_score\": weighted_score_val,\n",
    "        \"beta_score\": beta_score,\n",
    "        \"training_time\": training_time,\n",
    "        \"prediction_time\": prediction_time\n",
    "    }\n",
    "\n",
    "    with open(\"metrics.json\", \"w\") as f:\n",
    "        json.dump(metrics, f)\n",
    "    mlflow.log_artifact(\"metrics.json\")\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Best model parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision-Recall AUC: {pr_auc}\")\n",
    "    print(f\"Weighted Score: {weighted_score_val}\")\n",
    "    print(f\"Beta Score: {beta_score}\")\n",
    "    print(f\"Prediction time: {prediction_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a pipeline, extract the model\n",
    "lgb_model = best_model.named_steps['classifier']\n",
    "\n",
    "# Create a SHAP explainer using the raw data before transformation\n",
    "explainer = shap.Explainer(lgb_model, X_train)\n",
    "\n",
    "# Compute SHAP values for the test set\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Summary plot (global view of feature importances)\n",
    "shap.summary_plot(shap_values, X_test, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMMENTAIRE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a specific client's data \n",
    "client_index = 0  # Change this to target a specific client\n",
    "client_data = X_test[client_index:client_index+1]\n",
    "\n",
    "# Get SHAP values for this specific client\n",
    "shap_values_client = explainer(client_data)\n",
    "\n",
    "# Pass feature names directly to the SHAP values for visualization\n",
    "shap_values_client.data = client_data  # Actual values for the client\n",
    "shap_values_client.feature_names = feature_names  # Attach feature names\n",
    "\n",
    "# Waterfall plot for a single client\n",
    "shap.plots.waterfall(shap_values_client[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are wondering if the important features variation depending on the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the indices of the different cases\n",
    "false_positives = (y_pred == 1) & (y_test == 0)\n",
    "false_negatives = (y_pred == 0) & (y_test == 1)\n",
    "true_positives = (y_pred == 1) & (y_test == 1)\n",
    "true_negatives = (y_pred == 0) & (y_test == 0)\n",
    "\n",
    "# Helper function to safely get the index\n",
    "def get_first_index(case, case_name):\n",
    "    if case.sum() > 0:  # Check if there are any instances of this case\n",
    "        return np.where(case)[0][0]  # Return the first index where the condition is True\n",
    "    else:\n",
    "        print(f\"No instances of {case_name} found.\")\n",
    "        return None\n",
    "\n",
    "# Get the index for each case\n",
    "fp_index = get_first_index(false_positives, \"False Positive\")\n",
    "fn_index = get_first_index(false_negatives, \"False Negative\")\n",
    "tp_index = get_first_index(true_positives, \"True Positive\")\n",
    "tn_index = get_first_index(true_negatives, \"True Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# List of client indices\n",
    "client_indices = {\n",
    "    'False Positive': fp_index,\n",
    "    'False Negative': fn_index,\n",
    "    'True Positive': tp_index,\n",
    "    'True Negative': tn_index\n",
    "}\n",
    "\n",
    "# Loop over each category and plot the local feature importance using SHAP\n",
    "for label, client_index in client_indices.items():\n",
    "    print(f\"Generating SHAP Waterfall plot for {label} client\")\n",
    "\n",
    "    # Select the client's data\n",
    "    client_data = X_test[client_index:client_index+1]\n",
    "\n",
    "    # Get SHAP values for this specific client\n",
    "    shap_values_client = explainer(client_data)\n",
    "\n",
    "    # Set the feature names\n",
    "    shap_values_client.feature_names = feature_names\n",
    "\n",
    "    # Waterfall plot for the specific client\n",
    "    shap.plots.waterfall(shap_values_client[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
